{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z5JLpSjQa2KJkL1JEuK27diPuhRiXLoS",
      "authorship_tag": "ABX9TyPXbvxeXm/OqQ1MwFrcqAID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saitejasri1/Shared-ML-project/blob/final-from-prit/PaddleOCR-final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcoQNReRGBsD",
        "outputId": "6dfca360-f6bc-45db-86ec-6f2356d034f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddlepaddle-gpu==2.3.0 -i https://mirror.baidu.com/pypi/simple\n",
        "!pip install paddleocr\n",
        "# git clone https://github.com/PaddlePaddle/PaddleOCR\n",
        "!pip install PaddleOCR\n",
        "!pip install langdetect\n",
        "!pip install paddlepaddle\n",
        "\n",
        "#German to English\n",
        "\n",
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "id": "mxb5f_NaE1n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from paddleocr import PaddleOCR\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from googletrans import Translator\n",
        "from langdetect import detect\n",
        "import logging\n",
        "\n",
        "# Suppress debug messages from ppocr\n",
        "logging.getLogger(\"ppocr\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"ppocr\").setLevel(logging.ERROR)\n",
        "\n",
        "def detect_ingredients_from_images(N, image_paths):\n",
        "    \"\"\"\n",
        "    Perform OCR on the input image files to detect ingredients.\n",
        "\n",
        "    Args:\n",
        "    N (int): Number of times to run the process.\n",
        "    image_paths (list): List of paths to the image files.\n",
        "\n",
        "    Returns:\n",
        "    list: List of strings containing comma-separated detected ingredients for each image.\n",
        "    \"\"\"\n",
        "    # Setup OCR model with English language\n",
        "    ocr_model = PaddleOCR(lang='en')\n",
        "\n",
        "    # Define the list of ingredients\n",
        "    ingredients = {'beans', 'salt', 'butter', 'sugar', 'onion', 'water', 'eggs', 'oliveoil', 'flour', 'milk',\n",
        "                   'garliccloves', 'pepper', 'brownsugar', 'garlic', 'all-purposeflour', 'bakingpowder', 'egg',\n",
        "                   'saltandpepper', 'parmesancheese', 'lemonjuice', 'bakingsoda', 'vegetableoil', 'vanilla',\n",
        "                   'blackpepper', 'cinnamon', 'tomatoes', 'sourcream', 'garlicpowder', 'vanillaextract', 'oil',\n",
        "                   'honey', 'onions', 'creamcheese', 'garlicclove', 'celery', 'cheddarcheese', 'unsaltedbutter',\n",
        "                   'soysauce'}\n",
        "\n",
        "    # Initialize an empty list to store results for each image\n",
        "    all_detected_ingredients = []\n",
        "\n",
        "    for _ in range(N):\n",
        "        # Initialize an empty list to store detected ingredients for this iteration\n",
        "        detected_ingredients_iteration = []\n",
        "\n",
        "        for image_path in image_paths:\n",
        "            # Check if the image is in HEIC format\n",
        "            if image_path.lower().endswith('.heic'):\n",
        "                # Convert HEIC image to PNG format\n",
        "                heic_img = Image.open(image_path)\n",
        "                image_np = np.array(heic_img.convert('RGB'))\n",
        "            else:\n",
        "                # Load the image\n",
        "                image = Image.open(image_path)\n",
        "                # Convert image to numpy array\n",
        "                image_np = np.array(image)\n",
        "\n",
        "            # Perform OCR on the image\n",
        "            result = ocr_model.ocr(image_np)\n",
        "\n",
        "            # Extract text from OCR result\n",
        "            text = \"\"\n",
        "            if result is not None:\n",
        "                for line in result:\n",
        "                    for word in line:\n",
        "                        text += word[1][0] + ' '\n",
        "            else:\n",
        "                print(\"No text detected in image:\", image_path)\n",
        "\n",
        "            # Check if the detected text is in English\n",
        "            if detect(text) != 'en':\n",
        "                # Translate text to English\n",
        "                translator = Translator()\n",
        "                translated = translator.translate(text, src='auto', dest='en')\n",
        "                text = translated.text\n",
        "\n",
        "            # Convert text to lowercase and split into words\n",
        "            text = text.lower().split()\n",
        "\n",
        "            # Find intersection of detected ingredients and predefined ingredients list\n",
        "            detected_ingredients = ingredients.intersection(text)\n",
        "\n",
        "            # Join detected ingredients into a comma-separated string\n",
        "            detected_ingredients_str = ','.join(detected_ingredients)\n",
        "\n",
        "            # Add detected ingredients string to the list for this iteration\n",
        "            detected_ingredients_iteration.append(detected_ingredients_str)\n",
        "\n",
        "        # Add the list of detected ingredients for this iteration to the main list\n",
        "        all_detected_ingredients.append(detected_ingredients_iteration)\n",
        "\n",
        "    return all_detected_ingredients\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "N = 1  # Number of times to run the process\n",
        "image_paths = [\"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/1.jpg\",\n",
        "               \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/2.jpg\"] * N  # Path(s) to image(s)\n",
        "\n",
        "detected_ingredients = detect_ingredients_from_images(N, image_paths)\n",
        "print(detected_ingredients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7erSlSri1T8w",
        "outputId": "27a3ea8b-cf3c-4dd4-e6a0-75ec6b2b8790"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['beans', 'sugar']]\n"
          ]
        }
      ]
    }
  ]
}