{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saitejasri1/Shared-ML-project/blob/final-from-prit/merged1.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13tX-6f5azRm",
        "outputId": "ebb47baf-9611-47e3-b3a6-e91dd108db1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCZ6vyL6aw5V"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle-gpu==2.3.0 -i https://mirror.baidu.com/pypi/simple\n",
        "!pip install paddleocr\n",
        "# git clone https://github.com/PaddlePaddle/PaddleOCR\n",
        "!pip install PaddleOCR\n",
        "!pip install langdetect\n",
        "!pip install paddlepaddle\n",
        "\n",
        "#German to English\n",
        "\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "from paddleocr import PaddleOCR\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from googletrans import Translator\n",
        "from langdetect import detect\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozBkMOyHa3gG",
        "outputId": "30e15647-2973-4d67-e5f4-0660449d3002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tlr4FXmQa6e_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from sklearn.metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "hunwZY24hK6C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix27X74mXmET",
        "outputId": "7d73d1cf-de86-4c79-8bed-a687affb4910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n"
          ]
        }
      ],
      "source": [
        "# Suppress debug messages from ppocr\n",
        "logging.getLogger(\"ppocr\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"ppocr\").setLevel(logging.ERROR)\n",
        "\n",
        "def process_images_and_detect_ingredients(N_ensemble, N_OCR, ensemble_image_paths, ocr_image_paths):\n",
        "    \"\"\"\n",
        "    Process images using Ensemble model and detect ingredients using PaddleOCR.\n",
        "\n",
        "    Args:\n",
        "    N_ensemble (int): Number of times to run the Ensemble process.\n",
        "    N_OCR (int): Number of times to run the OCR process.\n",
        "    ensemble_image_paths (list): List of paths to the images for Ensemble model.\n",
        "    ocr_image_paths (list): List of paths to the images for PaddleOCR.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - str: Comma-separated output keywords for Ensemble model.\n",
        "        - list: List of strings containing comma-separated detected ingredients for each OCR image.\n",
        "    \"\"\"\n",
        "    # Ensemble model\n",
        "    def process_images(N, image_paths):\n",
        "        results = []\n",
        "\n",
        "        # Load pre-trained models\n",
        "        VGG16 = load_model('/content/drive/MyDrive/do-not-delete/ML-Project/VGG16.keras')\n",
        "        DenseNet121 = load_model('/content/drive/MyDrive/do-not-delete/ML-Project/InceptionV3.keras')\n",
        "        InceptionV3 = load_model('/content/drive/MyDrive/do-not-delete/ML-Project/InceptionV3.keras')\n",
        "\n",
        "        for path in image_paths:\n",
        "            input_image = tf.io.read_file(path)\n",
        "            image = tf.image.decode_image(input_image, channels=3)\n",
        "\n",
        "            image = tf.image.resize(image, size=(224, 224))\n",
        "            image = image / 255.0\n",
        "            image = tf.expand_dims(image, axis=0)\n",
        "\n",
        "            pred_probs_VGG16 = VGG16.predict(image)\n",
        "            pred_probs_DenseNet121 = DenseNet121.predict(image)\n",
        "            pred_probs_InceptionV3 = InceptionV3.predict(image)\n",
        "\n",
        "            ensemble_pred = np.maximum.reduce([pred_probs_VGG16, pred_probs_DenseNet121, pred_probs_InceptionV3])\n",
        "\n",
        "            predicted_label = np.argmax(ensemble_pred)\n",
        "            pred_prob = ensemble_pred[0][predicted_label]\n",
        "\n",
        "            # Output label handling\n",
        "            class_names = ['class1', 'class2', 'class3', 'class4', 'class5']  # Define class names here\n",
        "            if predicted_label < len(class_names):\n",
        "              output_label = class_names[predicted_label]\n",
        "            else:\n",
        "              output_label = \"Unknown\"\n",
        "            results.append(output_label)  # Append the output label to results list\n",
        "\n",
        "        return ','.join(results)  # Join all output labels with commas and return\n",
        "\n",
        "    # PaddleOCR model\n",
        "    def detect_ingredients_from_images(N, image_paths):\n",
        "        # Setup OCR model with English language\n",
        "        ocr_model = PaddleOCR(lang='en')\n",
        "\n",
        "        # Define the list of ingredients\n",
        "        ingredients = {'beans', 'salt', 'butter', 'sugar', 'onion', 'water', 'eggs', 'oliveoil', 'flour', 'milk',\n",
        "                       'garliccloves', 'pepper', 'brownsugar', 'garlic', 'all-purposeflour', 'bakingpowder', 'egg',\n",
        "                       'saltandpepper', 'parmesancheese', 'lemonjuice', 'bakingsoda', 'vegetableoil', 'vanilla',\n",
        "                       'blackpepper', 'cinnamon', 'tomatoes', 'sourcream', 'garlicpowder', 'vanillaextract', 'oil',\n",
        "                       'honey', 'onions', 'creamcheese', 'garlicclove', 'celery', 'cheddarcheese', 'unsaltedbutter',\n",
        "                       'soysauce'}\n",
        "\n",
        "        # Initialize an empty list to store results for each image\n",
        "        all_detected_ingredients = []\n",
        "\n",
        "        for _ in range(N):\n",
        "            # Initialize an empty list to store detected ingredients for this iteration\n",
        "            detected_ingredients_iteration = []\n",
        "\n",
        "            for image_path in image_paths:\n",
        "                # Check if the image is in HEIC format\n",
        "                if image_path.lower().endswith('.heic'):\n",
        "                    # Convert HEIC image to PNG format\n",
        "                    heic_img = Image.open(image_path)\n",
        "                    image_np = np.array(heic_img.convert('RGB'))\n",
        "                else:\n",
        "                    # Load the image\n",
        "                    image = Image.open(image_path)\n",
        "                    # Convert image to numpy array\n",
        "                    image_np = np.array(image)\n",
        "\n",
        "                # Perform OCR on the image\n",
        "                result = ocr_model.ocr(image_np)\n",
        "\n",
        "                # Extract text from OCR result\n",
        "                text = \"\"\n",
        "                if result is not None:\n",
        "                    for line in result:\n",
        "                        for word in line:\n",
        "                            text += word[1][0] + ' '\n",
        "                else:\n",
        "                    print(\"No text detected in image:\", image_path)\n",
        "\n",
        "                # Check if the detected text is in English\n",
        "                if detect(text) != 'en':\n",
        "                    # Translate text to English\n",
        "                    translator = Translator()\n",
        "                    translated = translator.translate(text, src='auto', dest='en')\n",
        "                    text = translated.text\n",
        "\n",
        "                # Convert text to lowercase and split into words\n",
        "                text = text.lower().split()\n",
        "\n",
        "                # Find intersection of detected ingredients and predefined ingredients list\n",
        "                detected_ingredients = ingredients.intersection(text)\n",
        "\n",
        "                # Join detected ingredients into a comma-separated string\n",
        "                detected_ingredients_str = ','.join(detected_ingredients)\n",
        "\n",
        "                # Add detected ingredients string to the list for this iteration\n",
        "                detected_ingredients_iteration.append(detected_ingredients_str)\n",
        "\n",
        "            # Add the list of detected ingredients for this iteration to the main list\n",
        "            all_detected_ingredients.append(detected_ingredients_iteration)\n",
        "\n",
        "        return all_detected_ingredients\n",
        "\n",
        "    # Execute Ensemble model\n",
        "    output_Ensemble = process_images(N_ensemble, ensemble_image_paths)\n",
        "\n",
        "    # Execute PaddleOCR model\n",
        "    detected_ingredients = detect_ingredients_from_images(N_OCR, ocr_image_paths)\n",
        "\n",
        "    return output_Ensemble, detected_ingredients\n",
        "\n",
        "# RecipeNLG model\n",
        "def load_data(filepath):\n",
        "    \"\"\" Load the dataset and preprocess the NER column \"\"\"\n",
        "    data = pd.read_csv(filepath)\n",
        "    data['ingredients'] = data['ingredients'].apply(eval)  # Convert ingredients from string to list\n",
        "    return data\n",
        "\n",
        "def build_tfidf_model(data):\n",
        "    \"\"\" Build and return a TF-IDF model and matrix \"\"\"\n",
        "    tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(data['ingredients'])\n",
        "    return tfidf_vectorizer, tfidf_matrix\n",
        "\n",
        "def find_similar_recipes(user_input, tfidf_vectorizer, tfidf_matrix, data):\n",
        "    \"\"\" Find and return similar recipes based on user input \"\"\"\n",
        "    # Transform user input using the same tfidf vectorizer\n",
        "    user_tfidf = tfidf_vectorizer.transform([user_input])\n",
        "    # Calculate cosine similarities between user input and all recipes\n",
        "    cosine_similarities = cosine_similarity(user_tfidf, tfidf_matrix)\n",
        "    # Get the indices of recipes sorted by the number of ingredient matches\n",
        "    sorted_indices = cosine_similarities.argsort()[0][::-1]\n",
        "    # Return top 20 similar recipes with max n matches\n",
        "    similar_recipes = data.iloc[sorted_indices[:20]][['title', 'ingredients', 'directions', 'link']]\n",
        "    return similar_recipes\n",
        "\n",
        "# Main execution flow\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to images for Ensemble model\n",
        "    ensemble_image_paths = [\"/content/drive/MyDrive/do-not-delete/ML-Project/Images/Ensemble/1.jpg\",\n",
        "                            \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/Ensemble/2.jpg\",\n",
        "                            \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/Ensemble/3.jpg\",\n",
        "                            \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/Ensemble/4.jpg\",\n",
        "                            \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/Ensemble/5.jpg\"]\n",
        "\n",
        "    # Paths to images for PaddleOCR model\n",
        "    ocr_image_paths = [\"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/1.jpg\",\n",
        "                       \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/2.jpg\",\n",
        "                       \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/3.jpg\",\n",
        "                       \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/4.jpg\",\n",
        "                       \"/content/drive/MyDrive/do-not-delete/ML-Project/Images/for_OCR/5.jpg\"]\n",
        "\n",
        "    # Execute Ensemble and PaddleOCR models\n",
        "    output_Ensemble, detected_ingredients = process_images_and_detect_ingredients(1, 1, ensemble_image_paths, ocr_image_paths)\n",
        "\n",
        "    # Load the dataset for RecipeNLG\n",
        "    filepath = '/content/drive/MyDrive/do-not-delete/ML-Project/RecipeNLG/RecipeNLG-all.csv'\n",
        "    data = load_data(filepath)\n",
        "\n",
        "    # Build the TF-IDF model and matrix\n",
        "    tfidf_vectorizer, tfidf_matrix = build_tfidf_model(data)\n",
        "\n",
        "    # Flatten the list of lists into a single list of strings\n",
        "    detected_ingredients_flat = [','.join(ingredients) for ingredients in detected_ingredients]\n",
        "\n",
        "    # Merge output keywords from Ensemble and detected ingredients from PaddleOCR\n",
        "    user_input = output_Ensemble + ',' + ','.join(detected_ingredients_flat)\n",
        "\n",
        "    # Find similar recipes\n",
        "    similar_recipes = find_similar_recipes(user_input, tfidf_vectorizer, tfidf_matrix, data)\n",
        "    print(\"Recommended Recipes Based on Your Ingredients:\")\n",
        "    print(similar_recipes)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa3B/uG/N8qi7Yl7Os7TPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}